{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom skimage import io\nfrom torchvision.transforms.functional import InterpolationMode as IMode\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:36.053805Z","iopub.execute_input":"2022-01-16T16:22:36.054125Z","iopub.status.idle":"2022-01-16T16:22:38.327373Z","shell.execute_reply.started":"2022-01-16T16:22:36.054091Z","shell.execute_reply":"2022-01-16T16:22:38.326438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation","metadata":{}},{"cell_type":"code","source":"class DatasetSuperResolution(Dataset):\n\n    def __init__(\n            self,\n            path_to_data: str,\n            mode: str = 'train',\n            image_size: int = 1080,\n            upscale_factor: int = 4\n\n    ):\n        super(DatasetSuperResolution, self).__init__()\n\n        self.files = [os.path.join(path_to_data, x) for x in os.listdir(path_to_data)]\n\n        if mode == \"train\":\n            self.hr_transforms = transforms.Compose([\n                transforms.RandomCrop(image_size, pad_if_needed = True)\n            ])\n        else:\n            self.hr_transforms = transforms.CenterCrop(image_size, pad_if_needed = True)\n\n        self.lr_transforms = transforms.Resize(\n            image_size // upscale_factor,\n            interpolation = IMode.BICUBIC,\n            antialias = True\n        )\n\n    def __getitem__(self, _index: int) -> [torch.Tensor, torch.Tensor]:\n        image = io.imread(self.files[_index])\n        image = transforms.ToTensor()(image)\n\n        hr_image = self.hr_transforms(image)\n        lr_image = self.lr_transforms(hr_image)\n\n        return lr_image, hr_image\n\n    def __len__(self) -> int:\n        return len(self.files)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:38.329187Z","iopub.execute_input":"2022-01-16T16:22:38.329446Z","iopub.status.idle":"2022-01-16T16:22:38.341553Z","shell.execute_reply.started":"2022-01-16T16:22:38.32941Z","shell.execute_reply":"2022-01-16T16:22:38.340624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = DatasetSuperResolution('/kaggle/input/div2k/DIV2K_train_HR/DIV2K_train_HR/', image_size=256, upscale_factor=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:39.182674Z","iopub.execute_input":"2022-01-16T16:22:39.183484Z","iopub.status.idle":"2022-01-16T16:22:39.677683Z","shell.execute_reply.started":"2022-01-16T16:22:39.183434Z","shell.execute_reply":"2022-01-16T16:22:39.676897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_set = DatasetSuperResolution('/kaggle/input/div2k/DIV2K_valid_HR/DIV2K_valid_HR/', image_size=256, upscale_factor=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:39.679285Z","iopub.execute_input":"2022-01-16T16:22:39.679532Z","iopub.status.idle":"2022-01-16T16:22:39.730913Z","shell.execute_reply.started":"2022-01-16T16:22:39.679494Z","shell.execute_reply":"2022-01-16T16:22:39.730283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(train_set,\n                            batch_size = 4,\n                            shuffle = True,\n                            num_workers = 2,\n                            pin_memory = True)\n\ndataloader_valid = DataLoader(valid_set, batch_size=2,\n                             shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:39.73251Z","iopub.execute_input":"2022-01-16T16:22:39.732764Z","iopub.status.idle":"2022-01-16T16:22:39.737677Z","shell.execute_reply.started":"2022-01-16T16:22:39.73273Z","shell.execute_reply":"2022-01-16T16:22:39.736864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in dataloader:\n    fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n    axs[0].imshow(x[0].squeeze().permute(1,2,0))\n    axs[1].imshow(y[0].squeeze().permute(1,2,0))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-14T13:40:40.79281Z","iopub.execute_input":"2022-01-14T13:40:40.793557Z","iopub.status.idle":"2022-01-14T13:40:47.406543Z","shell.execute_reply.started":"2022-01-14T13:40:40.793507Z","shell.execute_reply":"2022-01-14T13:40:47.405766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:42.534619Z","iopub.execute_input":"2022-01-16T16:22:42.535207Z","iopub.status.idle":"2022-01-16T16:22:42.586025Z","shell.execute_reply.started":"2022-01-16T16:22:42.535167Z","shell.execute_reply":"2022-01-16T16:22:42.585372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvResBlock(nn.Module):\n    \"\"\"\n    This is an implementation of a Residual Convolution Block from the article:\n        https://arxiv.org/pdf/1609.04802.pdf\n    \"\"\"\n\n    def __init__(\n            self,\n            channels: int = 64\n    ):\n        \"\"\"\n        :param channels: int\n            How many channels should be in convolutional blocks\n        \"\"\"\n        self.channels = channels\n        super(ConvResBlock, self).__init__()\n\n        self.conv_res_block = nn.Sequential(\n            nn.Conv2d(\n                in_channels = self.channels,\n                out_channels = self.channels,\n                kernel_size = 3,\n                stride = 1,\n                padding = 1\n            ),\n            nn.BatchNorm2d(self.channels),\n            nn.PReLU(),\n            nn.Conv2d(\n                in_channels = self.channels,\n                out_channels = self.channels,\n                kernel_size = 3,\n                stride = 1,\n                padding = 1,\n                bias = False\n            ),\n            nn.BatchNorm2d(self.channels)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass of Residual Convolution Block\n        :param x: torch.Tensor\n            Input tensor\n        :return: torch.Tensor\n            Output tensor\n        \"\"\"\n        initial_state = x\n        out = self.conv_res_block(x)\n        out = torch.add(out, initial_state)\n        return out\n\n\nclass Generator(nn.Module):\n    \"\"\"\n    Generator implementation of SRGAN from the article:\n        https://arxiv.org/pdf/1609.04802.pdf\n    \"\"\"\n\n    def __init__(\n            self,\n            input_channels: int = 3,\n            out_channels: int = 64,\n            input_kernel_size: int = 9,\n            input_stride: int = 1,\n            num_of_res_layers: int = 5\n    ):\n        super(Generator, self).__init__()\n\n        self.input_channels = input_channels\n        self.out_channels = out_channels\n        self.input_kernel = input_kernel_size\n        self.input_stride = input_stride\n        self.first_conv_padding = int(np.ceil((self.input_kernel - self.input_stride) / 2))\n\n        self.conv_1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels = self.input_channels,\n                out_channels = self.out_channels,\n                kernel_size = self.input_kernel,\n                stride = self.input_stride,\n                padding = self.first_conv_padding\n            ),\n            nn.PReLU()\n        )\n\n        residual_block = []\n        for i in range(num_of_res_layers):\n            residual_block.append(ConvResBlock(self.out_channels))\n        self.residual_block = nn.Sequential(*residual_block)\n\n        self.conv_2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels = self.out_channels,\n                out_channels = self.out_channels,\n                kernel_size = 3,\n                stride = 1,\n                padding = 1\n            ),\n            nn.BatchNorm2d(self.out_channels)\n        )\n        self.conv_3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels = self.out_channels,\n                out_channels = 256,\n                kernel_size = 3,\n                stride = 1,\n                padding = 1\n            ),\n            nn.PixelShuffle(2),\n            nn.PReLU(),\n            nn.Conv2d(\n                in_channels = self.out_channels,\n                out_channels = 256,\n                kernel_size = 3,\n                stride = 1,\n                padding = 1\n            ),\n            nn.PixelShuffle(2),\n            nn.PReLU(),\n        )\n\n        self.conv_4 = nn.Conv2d(\n            in_channels = self.out_channels,\n            out_channels = 3,\n            kernel_size = self.input_kernel,\n            stride = self.input_stride,\n            padding = self.first_conv_padding\n        )\n\n        self._initialize_weights()\n\n    def _initialize_weights(self) -> None:\n        \"\"\"\n        Weights initialization.\n        For convolutional blocks there is \"He initialization\".\n        :return:\n            None\n        \"\"\"\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d):\n                nn.init.kaiming_normal_(module.weight)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0)\n            elif isinstance(module, nn.BatchNorm2d):\n                nn.init.constant_(module.weight, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass of Generator\n        :param x: torch.tensor\n            Input Tensor\n        :return: torch.Tensor\n            Output tensor\n        \"\"\"\n        output_1 = self.conv_1(x)\n        output_2 = self.residual_block(output_1)\n        output = self.conv_2(output_2)\n        output = torch.add(output, output_1)\n        output = self.conv_3(output)\n        output = self.conv_4(output)\n\n        return output\n\n\"\"\"\nDiscriminator's block of the model\n\"\"\"\n\nclass convBlockDiscriminator(nn.Module):\n    '''\n    Block in the discriminator with different stride and in/out channels.\n    '''\n    def __init__(self,\n               stride_size: int = 1,\n               in_channels_size: int = 64,\n               out_channels_size: int = 64\n               ):\n        super(convBlockDiscriminator, self).__init__()\n\n        self.conv_block = nn.Sequential(nn.Conv2d(kernel_size=3, in_channels=in_channels_size, out_channels=out_channels_size, stride=stride_size),\n                                        nn.BatchNorm2d(out_channels_size), \n                                        nn.LeakyReLU(inplace=True)\n                                        )\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.conv_block(x)\n\n\nclass Discriminator(nn.Module):\n    \"\"\"\n    Discriminator implementation of SRGAN from the article:\n        https://arxiv.org/pdf/1609.04802.pdf\n    \"\"\"\n    def __init__(self,\n               in_channels_size: int = 3,\n               out_channels_size: int = 64,\n               layer_size: int = 1000\n               ):\n    \n\n        super(Discriminator, self).__init__()\n\n\n        self.conv_start_block = nn.Sequential(nn.Conv2d(kernel_size=3,\n                                                        in_channels=in_channels_size,\n                                                        out_channels=out_channels_size,\n                                                        stride=1),\n                                              nn.LeakyReLU(inplace=True))\n\n        self.conv_blocks = nn.ModuleList()\n\n        self.conv_block_1 = convBlockDiscriminator(2, 64, 128)\n        self.conv_block_2 = convBlockDiscriminator(1, 128, 128)\n        self.conv_block_3 = convBlockDiscriminator(2, 128, 256)\n        self.conv_block_4 = convBlockDiscriminator(1, 256, 256)\n        self.conv_block_5 = convBlockDiscriminator(2, 256, 512)\n        self.conv_block_6 = convBlockDiscriminator(1, 512, 512)\n        self.conv_block_7 = convBlockDiscriminator(2, 512, 512)\n\n        self.linear_block = nn.Sequential(nn.Linear(512*13*13, layer_size),\n                                          nn.LeakyReLU(inplace=True),\n                                          nn.Linear(layer_size, 1))\n\n\n        self._initialize_weights()\n    def _initialize_weights(self) -> None:\n        \"\"\"\n        Weights initialization.\n        For convolutional blocks there is \"He initialization\".\n        :return:\n            None\n        \"\"\"\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d):\n                nn.init.kaiming_normal_(module.weight)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0)\n            elif isinstance(module, nn.BatchNorm2d):\n                nn.init.constant_(module.weight, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        '''\n        Forward pass of Discriminator\n        :param x: torch.tensor\n            Input Tensor\n        :return: torch.Tensor\n            Output tensor\n        '''\n        out = self.conv_start_block(x)\n\n        out = self.conv_block_1(out)\n        out = self.conv_block_2(out)\n        out = self.conv_block_3(out)\n        out = self.conv_block_4(out)\n        out = self.conv_block_5(out)\n        out = self.conv_block_6(out)\n        out = self.conv_block_7(out)\n\n        out = out.flatten(start_dim=1)\n\n\n        out = self.linear_block(out) \n\n        return F.sigmoid(out)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:42.946809Z","iopub.execute_input":"2022-01-16T16:22:42.947512Z","iopub.status.idle":"2022-01-16T16:22:42.983984Z","shell.execute_reply.started":"2022-01-16T16:22:42.947474Z","shell.execute_reply":"2022-01-16T16:22:42.983236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\n\ngenerator_loss = nn.MSELoss()\ndiscriminator_loss = nn.BCEWithLogitsLoss()\n\ngenerator_optimizer = torch.optim.Adam(generator.parameters(),\n                                  lr=1e-4)\ndiscriminator_optimizer = torch.optim.Adam(discriminator.parameters(),\n                                  lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T16:22:43.680819Z","iopub.execute_input":"2022-01-16T16:22:43.681377Z","iopub.status.idle":"2022-01-16T16:22:47.627351Z","shell.execute_reply.started":"2022-01-16T16:22:43.681342Z","shell.execute_reply":"2022-01-16T16:22:47.626593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_picture(dataload, generator, device):\n    generator.eval()\n    i = 0\n    for x, y in dataload:\n        with torch.no_grad():\n            i += 1\n            pred = generator(x.to(device))\n            loss = F.mse_loss(pred, y.to(device))\n            fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n            axs[0].imshow(pred[0].squeeze().permute(1,2,0).detach().cpu().numpy())\n            axs[0].set_title('loss = %s'%loss)\n            axs[1].imshow(y[0].squeeze().permute(1,2,0).detach().cpu().numpy())\n        if i==2:\n            break","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:29:59.988788Z","iopub.execute_input":"2022-01-14T14:29:59.989069Z","iopub.status.idle":"2022-01-14T14:29:59.998894Z","shell.execute_reply.started":"2022-01-14T14:29:59.989041Z","shell.execute_reply":"2022-01-14T14:29:59.998145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output\nfrom tqdm.notebook import tqdm\ndef train(\n    train_loader,\n    valid_loader,\n    generator,\n    discriminator,\n    gen_loss,\n    discr_loss,\n    gen_optim,\n    discr_optim,\n    device,\n    epochs: int\n):\n    best_params_generator = 0 \n    history_loss_hr = list()\n    history_loss_sr = list()\n    history_mse = list()\n    generator.train()\n    discriminator.train()\n    scheduler_dicr = lr_scheduler.StepLR(discr_optim, step_size=20, gamma=0.1)\n    scheduler_gener = lr_scheduler.StepLR(gen_optim, step_size=20, gamma=0.1)\n    i=0\n    for epoch in range(epochs):\n        print(\"epochs =  \", (i+1))\n        i += 1\n        generator.train()\n        discriminator.train()\n        for lr, hr in tqdm(train_loader):\n           \n            lr = lr.to(device)\n            hr = hr.to(device)\n\n            real_label = torch.full([lr.size(0), 1], 1.0, dtype = lr.dtype, device = device)\n            fake_label = torch.full([lr.size(0), 1], 0.0, dtype = lr.dtype, device = device)\n\n            sr = generator(lr)\n\n            for p in discriminator.parameters():\n                p.requires_grad = True\n\n            discr_optim.zero_grad()\n\n            hr_output = discriminator(hr)\n            discriminator_hr_loss = discriminator_loss(hr_output, real_label)\n            history_loss_hr.append(discriminator_hr_loss.item())\n            discriminator_hr_loss.backward()\n\n            sr_output = discriminator(sr)\n            discriminator_sr_loss = discriminator_loss(sr_output, fake_label)\n            history_loss_sr.append(discriminator_sr_loss.item())\n            discriminator_sr_loss.backward()\n\n            discr_optim.step()\n\n            for p in discriminator.parameters():\n                p.requires_grad = False\n\n            gen_optim.zero_grad()\n\n            #output = discriminator(sr)\n            generator_loss_tr = generator_loss(sr, hr)\n            history_mse.append(generator_loss_tr.item())\n            #total_loss = generator_loss_tr + discriminator_sr_loss\n            generator_loss_tr.backward()\n            gen_optim.step()\n            \n            scheduler_dicr.step()\n            scheduler_gener.step()\n        clear_output(True)\n        fig, axs = plt.subplots(1, 3, figsize=(10, 10), dpi=100)\n        axs[0].plot(history_loss_hr)\n        axs[0].set_title('Discriminator with real labels')\n        axs[1].plot(history_loss_sr)\n        axs[1].set_title('Discriminator with fake labels')\n        axs[2].plot(history_mse)\n        axs[2].set_title('MSE loss generator')\n        plt.show()\n        time.sleep(5)\n        clear_output(True)\n        j = 0\n        for x, y in valid_loader:\n            with torch.no_grad():\n                j += 1\n                pred = generator(x.to(device))\n                loss = F.mse_loss(pred, y.to(device))\n                fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n                axs[0].imshow(pred[0].squeeze().permute(1,2,0).detach().cpu().numpy())\n                axs[0].set_title('loss = %s'%loss)\n                axs[1].imshow(y[0].squeeze().permute(1,2,0).detach().cpu().numpy())\n                plt.show()\n            if j==1:\n                break\n        time.sleep(5)\n            \n    return history_loss_hr, history_loss_sr, history_mse","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:30:00.487023Z","iopub.execute_input":"2022-01-14T14:30:00.487331Z","iopub.status.idle":"2022-01-14T14:30:00.517119Z","shell.execute_reply.started":"2022-01-14T14:30:00.487294Z","shell.execute_reply":"2022-01-14T14:30:00.513127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_l_h, h_l_s, h_mse = train(dataloader, dataloader_valid, generator,\n                            discriminator, generator_loss, discriminator_loss,\n                           generator_optimizer, discriminator_optimizer, device, 40)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:30:01.259326Z","iopub.execute_input":"2022-01-14T14:30:01.259973Z","iopub.status.idle":"2022-01-14T15:39:37.20417Z","shell.execute_reply.started":"2022-01-14T14:30:01.259931Z","shell.execute_reply":"2022-01-14T15:39:37.203351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nprint('kirik lox')\ntime.sleep(10)\nprint('shuchy')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:02:49.352657Z","iopub.execute_input":"2022-01-14T14:02:49.353283Z","iopub.status.idle":"2022-01-14T14:02:59.368175Z","shell.execute_reply.started":"2022-01-14T14:02:49.353241Z","shell.execute_reply":"2022-01-14T14:02:59.36739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}